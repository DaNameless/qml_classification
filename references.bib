@incollection{Ayodele10,
author = {Taiwo Oladipupo Ayodele},
title = {Types of Machine Learning Algorithms},
booktitle = {New Advances in Machine Learning},
publisher = {IntechOpen},
address = {Rijeka},
year = {2010},
editor = {Yagang Zhang},
chapter = {3},
doi = {10.5772/9385},
url = {https://doi.org/10.5772/9385}
}

@misc{degruyterIntroductionQuantum,
	author = {Siddhartha Bhattacharyya},
	title = {1. {I}ntroduction to quantum machine learning --- degruyter.com},
	howpublished = {\url{https://www.degruyter.com/document/doi/10.1515/9783110670707-001/html?lang=en&srsltid=AfmBOooSaEWc-Lhu5Q72P5vuHWm_Y-YgM6DHeMRsIa9RGnSxPbyiBfNP}},
	year = {},
	note = {[Accessed 09-03-2025]}
}

@book{Nielsen_Chuang_2010, place={Cambridge}, title={Quantum Computation and Quantum Information: 10th Anniversary Edition}, publisher={Cambridge University Press}, author={Nielsen, Michael A. and Chuang, Isaac L.}, year={2010}}


@inproceedings{10047618,

  author={Gupta, Vratika and Mishra, Vinay Kumar and Singhal, Priyank and Kumar, Amit},

  booktitle={2022 11th International Conference on System Modeling \& Advancement in Research Trends (SMART)}, 

  title={An Overview of Supervised Machine Learning Algorithm}, 

  year={2022},

  volume={},

  number={},

  pages={87-92},

  abstract={Machine learning is a subset of Artificial intelligence. Algorithms for machine learning automatically learn from experience and improve from it without being explicitly programmed. Machine learning defines Supervised, Unsupervised and Reinforcement Learning. Supervised algorithms are worked on under guidance but unsupervised algorithms are worked on without guidance. Machine learning provides good accuracy in both the algorithms. This paper is describing machine learning methods, different types of supervised learning algorithms, comparison of machine learning algorithms and application of machine learning algorithms.},

  keywords={Machine learning algorithms;Error analysis;Supervised learning;Reinforcement learning;Market research;Classification algorithms;Unsupervised learning;ANN;Naïve Bayes;Supervised learning;Machine learning},

  doi={10.1109/SMART55829.2022.10047618},
  
  url={https://ieeexplore.ieee.org/document/10047618},

  ISSN={2767-7362},

  month={Dec}}

@article{Arute2019,
abstract = {The promise of quantum computers is that certain computational tasks might be executed exponentially faster on a quantum processor than on a classical processor1. A fundamental challenge is to build a high-fidelity processor capable of running quantum algorithms in an exponentially large computational space. Here we report the use of a processor with programmable superconducting qubits2–7 to create quantum states on 53 qubits, corresponding to a computational state-space of dimension 253 (about 1016). Measurements from repeated experiments sample the resulting probability distribution, which we verify using classical simulations. Our Sycamore processor takes about 200 seconds to sample one instance of a quantum circuit a million times—our benchmarks currently indicate that the equivalent task for a state-of-the-art classical supercomputer would take approximately 10,000 years. This dramatic increase in speed compared to all known classical algorithms is an experimental realization of quantum supremacy8–14 for this specific computational task, heralding a much-anticipated computing paradigm. Quantum supremacy is demonstrated using a programmable superconducting processor known as Sycamore, taking approximately 200 seconds to sample one instance of a quantum circuit a million times, which would take a state-of-the-art supercomputer around ten thousand years to compute.},
author = {Arute, Frank and Arya, Kunal and Babbush, Ryan and Bacon, Dave and Bardin, Joseph C. and Barends, Rami and Biswas, Rupak and Boixo, Sergio and Brandao, Fernando G.S.L. and Buell, David A. and Burkett, Brian and Chen, Yu and Chen, Zijun and Chiaro, Ben and Collins, Roberto and Courtney, William and Dunsworth, Andrew and Farhi, Edward and Foxen, Brooks and Fowler, Austin and Gidney, Craig and Giustina, Marissa and Graff, Rob and Guerin, Keith and Habegger, Steve and Harrigan, Matthew P. and Hartmann, Michael J. and Ho, Alan and Hoffmann, Markus and Huang, Trent and Humble, Travis S. and Isakov, Sergei V. and Jeffrey, Evan and Jiang, Zhang and Kafri, Dvir and Kechedzhi, Kostyantyn and Kelly, Julian and Klimov, Paul V. and Knysh, Sergey and Korotkov, Alexander and Kostritsa, Fedor and Landhuis, David and Lindmark, Mike and Lucero, Erik and Lyakh, Dmitry and Mandr{\`{a}}, Salvatore and McClean, Jarrod R. and McEwen, Matthew and Megrant, Anthony and Mi, Xiao and Michielsen, Kristel and Mohseni, Masoud and Mutus, Josh and Naaman, Ofer and Neeley, Matthew and Neill, Charles and Niu, Murphy Yuezhen and Ostby, Eric and Petukhov, Andre and Platt, John C. and Quintana, Chris and Rieffel, Eleanor G. and Roushan, Pedram and Rubin, Nicholas C. and Sank, Daniel and Satzinger, Kevin J. and Smelyanskiy, Vadim and Sung, Kevin J. and Trevithick, Matthew D. and Vainsencher, Amit and Villalonga, Benjamin and White, Theodore and Yao, Z. Jamie and Yeh, Ping and Zalcman, Adam and Neven, Hartmut and Martinis, John M.},
doi = {10.1038/s41586-019-1666-5},
file = {:home/rolando/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arute et al. - 2019 - Quantum supremacy using a programmable superconducting processor.pdf:pdf},
issn = {1476-4687},
journal = {Nature 2019 574:7779},
keywords = {Quantum information,Quantum physics},
month = {oct},
number = {7779},
pages = {505--510},
pmid = {31645734},
publisher = {Nature Publishing Group},
title = {{Quantum supremacy using a programmable superconducting processor}},
url = {https://www.nature.com/articles/s41586-019-1666-5},
volume = {574},
year = {2019}
}

@inproceedings{ccalg,
author = {Tang, Ewin},
title = {A quantum-inspired classical algorithm for recommendation systems},
year = {2019},
isbn = {9781450367059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313276.3316310},
doi = {10.1145/3313276.3316310},
abstract = {We give a classical analogue to Kerenidis and Prakash’s quantum recommendation system, previously believed to be one of the strongest candidates for provably exponential speedups in quantum machine learning. Our main result is an algorithm that, given an m \texttimes{} n matrix in a data structure supporting certain ℓ2-norm sampling operations, outputs an ℓ2-norm sample from a rank-k approximation of that matrix in time O(poly(k)log(mn)), only polynomially slower than the quantum algorithm. As a consequence, Kerenidis and Prakash’s algorithm does not in fact give an exponential speedup over classical algorithms. Further, under strong input assumptions, the classical recommendation system resulting from our algorithm produces recommendations exponentially faster than previous classical systems, which run in time linear in m and n. The main insight of this work is the use of simple routines to manipulate ℓ2-norm sampling distributions, which play the role of quantum superpositions in the classical setting. This correspondence indicates a potentially fruitful framework for formally comparing quantum machine learning algorithms to classical machine learning algorithms.},
booktitle = {Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing},
pages = {217–228},
numpages = {12},
keywords = {sampling, recommender systems, quantum machine learning, low-rank approximation, exponential speedup},
location = {Phoenix, AZ, USA},
series = {STOC 2019}
}

@article{cq,
abstract = {We show how the quantum paradigm can be used to speed up unsupervised learning algorithms. More precisely, we explain how it is possible to accelerate learning algorithms by quantizing some of their subroutines. Quantization refers to the process that partially or totally converts a classical algorithm to its quantum counterpart in order to improve performance. In particular, we give quantized versions of clustering via minimum spanning tree, divisive clustering and k-medians that are faster than their classical analogues. We also describe a distributed version of k-medians that allows the participants to save on the global communication cost of the protocol compared to the classical version. Finally, we design quantum algorithms for the construction of a neighbourhood graph, outlier detection as well as smart initialization of the cluster centres. {\textcopyright} 2012 The Author(s).},
author = {A{\"{i}}meur, Esma and Brassard, Gilles and Gambs, S{\'{e}}bastien},
doi = {10.1007/S10994-012-5316-5/TABLES/1},
file = {:home/rolando/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/A{\"{i}}meur, Brassard, Gambs - 2013 - Quantum speed-up for unsupervised learning.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {Clustering,Grover's algorithm,Quantum information processing,Quantum learning,Unsupervised learning},
mendeley-groups = {QML review},
month = {feb},
number = {2},
pages = {261--287},
publisher = {Springer},
title = {{Quantum speed-up for unsupervised learning}},
url = {https://link.springer.com/article/10.1007/s10994-012-5316-5},
volume = {90},
year = {2013}
}

@article{charqc,
abstract = {Atomic-level qubits in silicon are attractive candidates for large-scale quantum computing; however, their quantum properties and controllability are sensitive to details such as the number of donor atoms comprising a qubit and their precise location. This work combines machine learning techniques with million-atom simulations of scanning tunnelling microscopic (STM) images of dopants to formulate a theoretical framework capable of determining the number of dopants at a particular qubit location and their positions with exact lattice site precision. A convolutional neural network (CNN) was trained on 100,000 simulated STM images, acquiring a characterisation fidelity (number and absolute donor positions) of >98% over a set of 17,600 test images including planar and blurring noise commensurate with experimental measurements. The formalism is based on a systematic symmetry analysis and feature-detection processing of the STM images to optimise the computational efficiency. The technique is demonstrated for qubits formed by single and pairs of closely spaced donor atoms, with the potential to generalise it for larger donor clusters. The method established here will enable a high-precision post-fabrication characterisation of dopant qubits in silicon, with high-throughput potentially alleviating the requirements on the level of resources required for quantum-based characterisation, which will otherwise be a challenge in the context of large qubit arrays for universal quantum computing.},
author = {Usman, Muhammad and Wong, Yi Zheng and Hill, Charles D. and Hollenberg, Lloyd C.L.},
doi = {10.1038/s41524-020-0282-0},
file = {:home/rolando/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Usman et al. - 2020 - Framework for atomic-level characterisation of quantum computer arrays by machine learning.pdf:pdf},
issn = {2057-3960},
journal = {npj Computational Materials 2020 6:1},
keywords = {Computational methods,Electronic devices,Electronic properties and materials},
mendeley-groups = {QML review},
month = {mar},
number = {1},
pages = {1--8},
publisher = {Nature Publishing Group},
title = {{Framework for atomic-level characterisation of quantum computer arrays by machine learning}},
url = {https://www.nature.com/articles/s41524-020-0282-0},
volume = {6},
year = {2020}
}
@article{controlqc,
abstract = {Emerging reinforcement learning techniques using deep neural networks have shown great promise in control optimization. They harness non-local regularities of noisy control trajectories and facilitate transfer learning between tasks. To leverage these powerful capabilities for quantum control optimization, we propose a new control framework to simultaneously optimize the speed and fidelity of quantum computation against both leakage and stochastic control errors. For a broad family of two-qubit unitary gates that are important for quantum simulation of many-electron systems, we improve the control robustness by adding control noise into training environments for reinforcement learning agents trained with trusted-region-policy-optimization. The agent control solutions demonstrate a two-order-of-magnitude reduction in average-gate-error over baseline stochastic-gradient-descent solutions and up to a one-order-of-magnitude reduction in gate time from optimal gate synthesis counterparts. These significant improvements in both fidelity and runtime are achieved by combining new physical understandings and state-of-the-art machine learning techniques. Our results open a venue for wider applications in quantum simulation, quantum chemistry and quantum supremacy tests using near-term quantum devices.},
author = {Niu, Murphy Yuezhen and Boixo, Sergio and Smelyanskiy, Vadim N. and Neven, Hartmut},
doi = {10.1038/s41534-019-0141-3},
file = {:home/rolando/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niu et al. - 2019 - Universal quantum control through deep reinforcement learning.pdf:pdf},
issn = {2056-6387},
journal = {npj Quantum Information 2019 5:1},
keywords = {Quantum information,Qubits},
mendeley-groups = {QML review},
month = {apr},
number = {1},
pages = {1--8},
publisher = {Nature Publishing Group},
title = {{Universal quantum control through deep reinforcement learning}},
url = {https://www.nature.com/articles/s41534-019-0141-3},
volume = {5},
year = {2019}
}
@article{readoutqc,
abstract = {Current methods for classifying measurement trajectories in superconducting qubit systems produce fidelities systematically lower than those predicted by experimental parameters. Here, we place current classification methods within the framework of machine learning (ML) algorithms and improve on them by investigating more sophisticated ML approaches. We find that nonlinear algorithms and clustering methods produce significantly higher assignment fidelities that help close the gap to the fidelity possible under ideal noise conditions. Clustering methods group trajectories into natural subsets within the data, which allows for the diagnosis of systematic errors. We find large clusters in the data associated with T1 processes and show these are the main source of discrepancy between our experimental and ideal fidelities. These error diagnosis techniques help provide a path forward to improve qubit measurements.},
archivePrefix = {arXiv},
arxivId = {1411.4994},
author = {Magesan, Easwar and Gambetta, Jay M. and C{\'{o}}rcoles, A. D. and Chow, Jerry M.},
doi = {10.1103/PHYSREVLETT.114.200501/FIGURES/6/THUMBNAIL},
eprint = {1411.4994},
issn = {10797114},
journal = {Physical Review Letters},
mendeley-groups = {QML review},
month = {may},
number = {20},
pages = {200501},
publisher = {American Physical Society},
title = {{Machine Learning for Discriminating Quantum Measurement Trajectories and Improving Readout}},
url = {https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.114.200501},
volume = {114},
year = {2015}
}

@article{10613907,
  author={Reka, S. Sofana and Karthikeyan, H. Leela and Shakil, A. Jack and Venugopal, Prakash and Muniraj, Manigandan},
  journal={IEEE Access}, 
  title={Exploring Quantum Machine Learning for Enhanced Skin Lesion Classification: A Comparative Study of Implementation Methods}, 
  year={2024},
  volume={12},
  number={},
  pages={104568-104584},
  keywords={Skin;Diseases;Accuracy;Computational modeling;Machine learning;Lesions;Machine learning algorithms;HAM10000 dataset;Qiskit;quantum machine learning;quanvolutional neural network;quantum support vector classifier;skin lesion;PennyLane},
  doi={10.1109/ACCESS.2024.3434681}
  }


@article{Lloyd2013,
   abstract = {Machine-learning tasks frequently involve problems of manipulating and classifying large numbers of vectors in high-dimensional spaces. Classical algorithms for solving such problems typically take time polynomial in the number of vectors and the dimension of the space. Quantum computers are good at manipulating high-dimensional vectors in large tensor product spaces. This paper provides supervised and unsupervised quantum machine learning algorithms for cluster assignment and cluster finding. Quantum machine learning can take time logarithmic in both the number of vectors and their dimension, an exponential speed-up over classical algorithms. In machine learning, information processors perform tasks of sorting, assembling, assimilating , and classifying information [1-2]. In supervised learning, the machine infers a function from a set of training examples. In unsupervised learning the machine tries to find hidden structure in unlabeled data. Recent studies and applications focus in particular on the problem of large-scale machine learning [2]-big data-where the training set and/or the number of features is large. Various results on quantum machine learning investigate the use of quantum information processors to perform machine learning tasks [3-9], including pattern matching [3], Probably Approximately Correct learning [4], feedback learning for quantum measurement [5], binary classifiers [6-7], and quantum support vector machines [8].},
   author = {Seth Lloyd and Masoud Mohseni and Patrick Rebentrost and Seth Lloyd and Masoud Mohseni and Patrick Rebentrost},
   doi = {10.48550/ARXIV.1307.0411},
   journal = {arXiv},
   keywords = {Quantum Physics},
   pages = {arXiv:1307.0411},
   title = {Quantum algorithms for supervised and unsupervised machine learning},
   url = {https://ui.adsabs.harvard.edu/abs/2013arXiv1307.0411L/abstract},
   year = {2013}
}
@article{swaptest,
   abstract = {Classical fingerprinting associates with each string a shorter string (its fingerprint), such that any two distinct strings can be distinguished with small error by comparing their fingerprints alone. The fingerprints cannot be made exponentially smaller than the original strings unless the parties preparing the fingerprints have access to correlated random sources. We show that fingerprints consisting of quantum information can be made exponentially smaller than the original strings without any correlations or entanglement between the parties. This implies an exponential quantum/classical gap for the equality problem in the simultaneous message passing model of communication complexity.},
   author = {Harry Buhrman and Richard Cleve and John Watrous and Ronald de Wolf},
   doi = {10.1103/PhysRevLett.87.167902},
   issn = {00319007},
   issue = {16},
   journal = {Physical Review Letters},
   month = {9},
   pages = {167902},
   pmid = {11690244},
   publisher = {American Physical Society},
   title = {Quantum Fingerprinting},
   volume = {87},
   url = {https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.87.167902},
   year = {2001}
}
@misc{kwak2021quantumneuralnetworksconcepts,
      title={Quantum Neural Networks: Concepts, Applications, and Challenges}, 
      author={Yunseok Kwak and Won Joon Yun and Soyi Jung and Joongheon Kim},
      year={2021},
      eprint={2108.01468},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/2108.01468}, 
}
@misc{farhi2018classificationquantumneuralnetworks,
      title={Classification with Quantum Neural Networks on Near Term Processors}, 
      author={Edward Farhi and Hartmut Neven},
      year={2018},
      eprint={1802.06002},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/1802.06002}, 
}
@misc{qiskittheory,
	author = {},
	title = {{Q}uantum {N}eural {N}etworks - {Q}iskit {M}achine {L}earning 0.8.2 --- qiskit-community.github.io},
	howpublished = {\url{https://qiskit-community.github.io/qiskit-machine-learning/tutorials/01_neural_networks.html}},
	year = {},
	note = {[Accessed 26-03-2025]},
}
@misc{kwon2024featuremapquantumdata,
      title={Feature Map for Quantum Data in Classification}, 
      author={Hyeokjea Kwon and Hojun Lee and Joonwoo Bae},
      year={2024},
      eprint={2303.15665},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/2303.15665}, 
}
@ARTICLE{10015720,
  author={Simões, Ricardo Daniel Monteiro and Huber, Patrick and Meier, Nicola and Smailov, Nikita and Füchslin, Rudolf M. and Stockinger, Kurt},
  journal={IEEE Access}, 
  title={Experimental Evaluation of Quantum Machine Learning Algorithms}, 
  year={2023},
  volume={11},
  number={},
  pages={6197-6208},
  keywords={Quantum computing;Qubit;Neural networks;Machine learning;Computers;Performance evaluation;Quantum mechanics;Machine learning;quantum computing;experimental evaluation},
  doi={10.1109/ACCESS.2023.3236409}}
@ARTICLE{9293291,
  author={Yumin, Dong and Wu, Mingqiu and Zhang, Jinlei},
  journal={IEEE Access}, 
  title={Recognition of Pneumonia Image Based on Improved Quantum Neural Network}, 
  year={2020},
  volume={8},
  number={},
  pages={224500-224512},
  keywords={Logic gates;Quantum computing;Lung;Diseases;Biological neural networks;Image recognition;Neurons;Quantum gate;pneumonia image recognition;quantum neural network;quantum particle swarm},
  doi={10.1109/ACCESS.2020.3044697}}
@INPROCEEDINGS{9528698,
  author={Kwak, Yunseok and Yun, Won Joon and Jung, Soyi and Kim, Joongheon},
  booktitle={2021 Twelfth International Conference on Ubiquitous and Future Networks (ICUFN)}, 
  title={Quantum Neural Networks: Concepts, Applications, and Challenges}, 
  year={2021},
  volume={},
  number={},
  pages={413-416},
  keywords={Deep learning;Training;Artificial neural networks;Quantum circuit},
  doi={10.1109/ICUFN49451.2021.9528698}}

@article{SMAILOVIC2014181,
title = {Stream-based active learning for sentiment analysis in the financial domain},
journal = {Information Sciences},
volume = {285},
pages = {181-203},
year = {2014},
note = {Processing and Mining Complex Data Streams},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2014.04.034},
url = {https://www.sciencedirect.com/science/article/pii/S0020025514004885},
author = {Jasmina Smailović and Miha Grčar and Nada Lavrač and Martin Žnidaršič},
keywords = {Predictive sentiment analysis, Stream-based active learning, Stock market, Twitter, Positive sentiment probability, Granger causality},
abstract = {Studying the relationship between public sentiment and stock prices has been the focus of several studies. This paper analyzes whether the sentiment expressed in Twitter feeds, which discuss selected companies and their products, can indicate their stock price changes. To address this problem, an active learning approach was developed and applied to sentiment analysis of tweet streams in the stock market domain. The paper first presents a static Twitter data analysis problem, explored in order to determine the best Twitter-specific text preprocessing setting for training the Support Vector Machine (SVM) sentiment classifier. In the static setting, the Granger causality test shows that sentiments in stock-related tweets can be used as indicators of stock price movements a few days in advance, where improved results were achieved by adapting the SVM classifier to categorize Twitter posts into three sentiment categories of positive, negative and neutral (instead of positive and negative only). These findings were adopted in the development of a new stream-based active learning approach to sentiment analysis, applicable in incremental learning from continuously changing financial tweet streams. To this end, a series of experiments was conducted to determine the best querying strategy for active learning of the SVM classifier adapted to sentiment analysis of financial tweet streams. The experiments in analyzing stock market sentiments of a particular company show that changes in positive sentiment probability can be used as indicators of the changes in stock closing prices.}
}

@article{gmd-16-6433-2023,
AUTHOR = {de Burgh-Day, C. O. and Leeuwenburg, T.},
TITLE = {Machine learning for numerical weather and climate modelling: a review},
JOURNAL = {Geoscientific Model Development},
VOLUME = {16},
YEAR = {2023},
NUMBER = {22},
PAGES = {6433--6477},
URL = {https://gmd.copernicus.org/articles/16/6433/2023/},
DOI = {10.5194/gmd-16-6433-2023}
}
@article{doi:10.1148/rg.2017160130,
author = {Erickson, Bradley J. and Korfiatis, Panagiotis and Akkus, Zeynettin and Kline, Timothy L.},
title = {Machine Learning for Medical Imaging},
journal = {RadioGraphics},
volume = {37},
number = {2},
pages = {505-515},
year = {2017},
doi = {10.1148/rg.2017160130},
    note ={PMID: 28212054},

URL = { 
    
        https://doi.org/10.1148/rg.2017160130
    
    

},
eprint = { 
    
        https://doi.org/10.1148/rg.2017160130
    
    

}
,
    abstract = { Machine learning is a technique for recognizing patterns that can be applied to medical images. Although it is a powerful tool that can help in rendering medical diagnoses, it can be misapplied. Machine learning typically begins with the machine learning algorithm system computing the image features that are believed to be of importance in making the prediction or diagnosis of interest. The machine learning algorithm system then identifies the best combination of these image features for classifying the image or computing some metric for the given image region. There are several methods that can be used, each with different strengths and weaknesses. There are open-source versions of most of these machine learning methods that make them easy to try and apply to images. Several metrics for measuring the performance of an algorithm exist; however, one must be aware of the possible associated pitfalls that can result in misleading metrics. More recently, deep learning has started to be used; this method has the benefit that it does not require image feature identification and calculation as a first step; rather, features are identified as part of the learning process. Machine learning has been used in medical imaging and will have a greater influence in the future. Those working in medical imaging must be aware of how machine learning works.©RSNA, 2017 }
}

@article{LIU2017159,
title = {Materials discovery and design using machine learning},
journal = {Journal of Materiomics},
volume = {3},
number = {3},
pages = {159-177},
year = {2017},
note = {High-throughput Experimental and Modeling Research toward Advanced Batteries},
issn = {2352-8478},
doi = {https://doi.org/10.1016/j.jmat.2017.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2352847817300515},
author = {Yue Liu and Tianlu Zhao and Wangwei Ju and Siqi Shi},
keywords = {New materials discovery, Materials design, Materials properties prediction, Machine learning},
abstract = {The screening of novel materials with good performance and the modelling of quantitative structure-activity relationships (QSARs), among other issues, are hot topics in the field of materials science. Traditional experiments and computational modelling often consume tremendous time and resources and are limited by their experimental conditions and theoretical foundations. Thus, it is imperative to develop a new method of accelerating the discovery and design process for novel materials. Recently, materials discovery and design using machine learning have been receiving increasing attention and have achieved great improvements in both time efficiency and prediction accuracy. In this review, we first outline the typical mode of and basic procedures for applying machine learning in materials science, and we classify and compare the main algorithms. Then, the current research status is reviewed with regard to applications of machine learning in material property prediction, in new materials discovery and for other purposes. Finally, we discuss problems related to machine learning in materials science, propose possible solutions, and forecast potential directions of future research. By directly combining computational studies with experiments, we hope to provide insight into the parameters that affect the properties of materials, thereby enabling more efficient and target-oriented research on materials discovery and design.}
}

@article{Franco2021,
   abstract = {Machine learning (ML), and particularly algorithms based on artificial neural networks (ANNs), constitute a field of research lying at the intersection of different disciplines such as mathematics, statistics, computer science and neuroscience. This approach is characterized by the use of algorithms to extract knowledge from large and heterogeneous data sets. In addition to offering a brief introduction to ANN algorithms-based ML, in this paper we will focus our attention on its possible applications in the social sciences and, in particular, on its potential in the data analysis procedures. In this regard, we will provide three examples of applications on sociological data to assess the impact of ML in the study of relationships between variables. Finally, we will compare the potential of ML with traditional data analysis models.},
   author = {Giovanni Di Franco and Michele Santurro},
   doi = {10.1007/s11135-020-01037-y},
   isbn = {0123456789},
   keywords = {Deep learning Artificial neural network,Linear models,Machine learning,Nonlinear models,Supervised learning},
   pages = {1007-1025},
   title = {Machine learning, artificial neural networks and social research},
   volume = {55},
   url = {https://doi.org/10.1007/s11135-020-01037-y},
   year = {2021},
   journal = {Quality and Quantity}
}

@article{Richards2019,
   abstract = {Systems neuroscience seeks explanations for how the brain implements a wide variety of perceptual, cognitive and motor tasks. Conversely, artificial intelligence attempts to design computational systems based on the tasks they will have to solve. In artificial neural networks, the three components specified by design are the objective functions, the learning rules and the architectures. With the growing success of deep learning, which utilizes brain-inspired architectures, these three designed components have increasingly become central to how we model, engineer and optimize complex artificial learning systems. Here we argue that a greater focus on these components would also benefit systems neuroscience. We give examples of how this optimization-based framework can drive theoretical and experimental progress in neuroscience. We contend that this principled perspective on systems neuroscience will help to generate more rapid progress. A deep network is best understood in terms of components used to design it—objective functions, architecture and learning rules—rather than unit-by-unit computation. Richards et al. argue that this inspires fruitful approaches to systems neuroscience.},
   author = {Blake A. Richards and Timothy P. Lillicrap and Philippe Beaudoin and Yoshua Bengio and Rafal Bogacz and Amelia Christensen and Claudia Clopath and Rui Ponte Costa and Archy de Berker and Surya Ganguli and Colleen J. Gillon and Danijar Hafner and Adam Kepecs and Nikolaus Kriegeskorte and Peter Latham and Grace W. Lindsay and Kenneth D. Miller and Richard Naud and Christopher C. Pack and Panayiota Poirazi and Pieter Roelfsema and João Sacramento and Andrew Saxe and Benjamin Scellier and Anna C. Schapiro and Walter Senn and Greg Wayne and Daniel Yamins and Friedemann Zenke and Joel Zylberberg and Denis Therien and Konrad P. Kording},
   doi = {10.1038/s41593-019-0520-2},
   issn = {1546-1726},
   issue = {11},
   journal = {Nature Neuroscience 2019 22:11},
   keywords = {Learning algorithms,Machine learning,Neural circuits},
   month = {10},
   pages = {1761-1770},
   pmid = {31659335},
   publisher = {Nature Publishing Group},
   title = {A deep learning framework for neuroscience},
   volume = {22},
   url = {https://www.nature.com/articles/s41593-019-0520-2},
   year = {2019}
}

@article{G2007,
   abstract = {Quantum associative memories are connectionist structures that demonstrate the particle-wave nature of information and are compatible with quantum mechanics postulates. Following the solution of Sc...},
   author = {RigatosG. G. and TzafestasS. G.},
   doi = {10.5555/1367089.1367091},
   journal = {Integrated Computer-Aided Engineering},
   month = {8},
   publisher = {IOS PressPUB827Amsterdam, The Netherlands, The Netherlands},
   title = {Neurodynamics and attractors in quantum associative memories},
   url = {https://dl.acm.org/doi/10.5555/1367089.1367091},
   year = {2007}
}

@article{SchuldMaria2014,
   abstract = {With the overwhelming success in the field of quantum information in the last decades, the `quest' for a Quantum Neural Network (QNN) model began in order to combine quantum computing with the stri...},
   author = {SchuldMaria and SinayskiyIlya and PetruccioneFrancesco},
   doi = {10.5555/2684509.2684546},
   journal = {Quantum Information Processing},
   keywords = {Artificial neural networks,Open quantum systems,Quantum Neural Networks,Quantum computing},
   month = {11},
   publisher = {Kluwer Academic PublishersPUB879Norwell, MA, USA},
   title = {The quest for a Quantum Neural Network},
   url = {https://dl.acm.org/doi/10.5555/2684509.2684546},
   year = {2014}
}

@misc{Liu2024,
      title={Training Classical Neural Networks by Quantum Machine Learning}, 
      author={Chen-Yu Liu and En-Jui Kuo and Chu-Hsuan Abraham Lin and Sean Chen and Jason Gemsun Young and Yeong-Jar Chang and Min-Hsiu Hsieh},
      year={2024},
      eprint={2402.16465},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/2402.16465}, 
}

@misc{Mathur2021,
      title={Medical image classification via quantum neural networks}, 
      author={Natansh Mathur and Jonas Landman and Yun Yvonna Li and Martin Strahm and Skander Kazdaghli and Anupam Prakash and Iordanis Kerenidis},
      year={2022},
      eprint={2109.01831},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/2109.01831}, 
}
@article{Sebastianelli2022,
   abstract = {This article aims to investigate how circuit-based hybrid quantum convolutional neural networks (QCNNs) can be successfully employed as image classifiers in the context of remote sensing. The hybrid QCNNs enrich the classical architecture of convolutional neural networks by introducing a quantum layer within a standard neural network. The novel QCNN proposed in this work is applied to the land-use and land-cover classification, chosen as an Earth observation (EO) use case, and tested on the EuroSAT dataset used as the reference benchmark. The results of the multiclass classification prove the effectiveness of the presented approach by demonstrating that the QCNN performances are higher than the classical counterparts. Moreover, investigation of various quantum circuits shows that the ones exploiting quantum entanglement achieve the best classification scores. This study underlines the potentialities of applying quantum computing to an EO case study and provides the theoretical and experimental background for future investigations.},
   author = {Alessandro Sebastianelli and Daniela Alessandra Zaidenberg and Dario Spiller and Bertrand Le Saux and Silvia Ullo},
   doi = {10.1109/JSTARS.2021.3134785},
   issn = {21511535},
   journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
   keywords = {Earth observation (EO),image classification,land-use and land-cover (LULC) classification,machine learning (ML),quantum computing (QC),quantum machine learning (QML),remote sensing},
   pages = {565-580},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {On Circuit-Based Hybrid Quantum Neural Networks for Remote Sensing Imagery Classification},
   volume = {15},
   year = {2022}
}
@article{Andrecut1998,
   abstract = {This paper combines quantum computation with classical neural network theory to produce a quantum computational learning algorithm. Quantum computation uses microscopic quantum level effects to perform computational tasks and has produced results that in some cases are exponentially faster than their classical counterparts. The unique characteristics of quantum theory may also be used to create a quantum associative memory with a capacity exponential in the number of neurons. This paper combines two quantum computational algorithms to produce such a quantum associative memory. The result is an exponential increase in the capacity of the memory when compared to traditional associative memories such as the Hopfield network. The paper covers necessary high-level quantum mechanical and quantum computational ideas and introduces a quantum associative memory. Theoretical analysis proves the utility of the memory, and it is noted that a small version should be physically realizable in the near future.},
   author = {M. Andrecut and M. K. Ali},
   doi = {10.1142/S0217979203018284},
   issn = {02179792},
   issue = {12},
   journal = {International Journal of Modern Physics B},
   keywords = {Associative memory,Neural networks,Quantum algorithms},
   month = {7},
   pages = {2447-2472},
   title = {Quantum Associative Memory},
   volume = {17},
   url = {https://arxiv.org/abs/quant-ph/9807053v1},
   year = {1998}
}
@article{Schtzhold2003,
   abstract = {By means of a simple example, it is demonstrated that the task of finding and identifying certain patterns in an otherwise (macroscopically) unstructured picture (dataset) can be accomplished efficiently by a quantum computer. Employing the powerful tool of the quantum Fourier transform, the proposed quantum algorithm exhibits an exponential speedup in comparison with its classical counterpart. © 2003 The American Physical Society.},
   author = {Ralf Schützhold},
   doi = {10.1103/PhysRevA.67.062311},
   issn = {10941622},
   issue = {6},
   journal = {Physical Review A},
   month = {6},
   pages = {062311},
   publisher = {American Physical Society},
   title = {Pattern recognition on a quantum computer},
   volume = {67},
   url = {https://journals.aps.org/pra/abstract/10.1103/PhysRevA.67.062311},
   year = {2003}
}
@article{Wiebe2014,
   abstract = {We present several quantum algorithms for performing nearest-neighbor learning. At the core of our algorithms are fast and coherent quantum methods for computing distance metrics such as the inner product and Euclidean distance. We prove upper bounds on the number of queries to the input data required to compute these metrics. In the worst case, our quantum algorithms lead to polynomial reductions in query complexity relative to the corresponding classical algorithm. In certain cases, we show exponential or even super-exponential reductions over the classical analog. We study the performance of our quantum nearest-neighbor algorithms on several real-world binary classification tasks and find that the classification accuracy is competitive with classical methods.},
   author = {Nathan Wiebe and Ashish Kapoor and Krysta M. Svore},
   doi = {10.26421/qic15.3-4-7},
   issn = {15337146},
   issue = {3-4},
   journal = {Quantum Information and Computation},
   keywords = {Machine Learning,Quantum Algorithms,Quantum Computing},
   month = {1},
   pages = {318-358},
   publisher = {Rinton Press Inc.},
   title = {Quantum Algorithms for Nearest-Neighbor Methods for Supervised and Unsupervised Learning},
   volume = {15},
   url = {https://arxiv.org/abs/1401.2142v2},
   year = {2014}
}
@article{Rebentrost2014,
   abstract = {Supervised machine learning is the classification of new data based on already classified training examples. In this work, we show that the support vector machine, an optimized binary classifier, can be implemented on a quantum computer, with complexity logarithmic in the size of the vectors and the number of training examples. In cases where classical sampling algorithms require polynomial time, an exponential speedup is obtained. At the core of this quantum big data algorithm is a nonsparse matrix exponentiation technique for efficiently performing a matrix inversion of the training data inner-product (kernel) matrix.},
   author = {Patrick Rebentrost and Masoud Mohseni and Seth Lloyd},
   doi = {10.1103/PhysRevLett.113.130503},
   issn = {10797114},
   issue = {13},
   journal = {Physical Review Letters},
   month = {9},
   pages = {130503},
   publisher = {American Physical Society},
   title = {Quantum Support Vector Machine for Big Data Classification},
   volume = {113},
   url = {https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.113.130503},
   year = {2014}
}
@article{Broadbent2015,
   abstract = {Quantum cryptography is the art and science of exploiting quantum mechanical effects in order to perform cryptographic tasks. While the most well-known example of this discipline is quantum key distribution (QKD), there exist many other applications such as quantum money, randomness generation, secure two- and multi-party computation and delegated quantum computation. Quantum cryptography also studies the limitations and challenges resulting from quantum adversaries—including the impossibility of quantum bit commitment, the difficulty of quantum rewinding and the definition of quantum security models for classical primitives. In this review article, aimed primarily at cryptographers unfamiliar with the quantum world, we survey the area of theoretical quantum cryptography, with an emphasis on the constructions and limitations beyond the realm of QKD.},
   author = {Anne Broadbent and Christian Schaffner and B Anne Broadbent abroadbe and uottawaca B Christian Schaffner cschaffner},
   doi = {10.1007/S10623-015-0157-4},
   issn = {1573-7586},
   issue = {1},
   journal = {Designs, Codes and Cryptography 2015 78:1},
   keywords = {Coding and Information Theory,Cryptology,Discrete Mathematics in Computer Science,Quantum key distribution,Quantum money,Quantum random oracle model,Quantum rewinding,Quantum two-party computation,Quantum two-party computations,Superposition queries,Survey},
   month = {12},
   pages = {351-382},
   publisher = {Springer},
   title = {Quantum cryptography beyond quantum key distribution},
   volume = {78},
   url = {https://link.springer.com/article/10.1007/s10623-015-0157-4},
   year = {2015}
}
@article{Farouk2018,
   abstract = {In this chapter the principles of quantum computing and communications has been proposed.},
   author = {Ahmed Farouk and O. Tarawneh and Mohamed Elhoseny and J. Batle and Mosayeb Naseri and Aboul Ella Hassanien and M. Abedl-Aty},
   doi = {10.1007/978-3-319-63639-9_4},
   issn = {21976511},
   journal = {Studies in Big Data},
   keywords = {Quantum data link layer,Quantum key distribution,Quantum-Back-Bone},
   pages = {63-100},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Quantum Computing and Cryptography: An Overview},
   volume = {33},
   year = {2018}
}
@article{Shor2006,
   abstract = {A digital computer is generally believed to be an efficient universal computing device; that is, it is believed able to simulate any physical computing device with an increase in computation time b...},
   author = {Peter W. Shor},
   doi = {10.1137/S0097539795293172},
   issn = {00975397},
   issue = {5},
   journal = {https://doi.org/10.1137/S0097539795293172},
   keywords = {03D10,11Y05,68Q10,81P10,Church's thesis,Fourier transforms,algorithmic number theory,discrete logarithms,foundations of quantum mechanics,prime factorization,quantum computers,spin systems},
   month = {7},
   pages = {1484-1509},
   publisher = {Society for Industrial and Applied Mathematics},
   title = {Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer},
   volume = {26},
   url = {https://epubs.siam.org/doi/10.1137/S0097539795293172},
   year = {2006}
}
@article{Grover1996,
   abstract = {An unsorted database contains N records, of which just one satisfies a particular property. The problem is to identify that one record. Any classical algorithm, deterministic or probabilistic, will clearly take O (N) steps since on the average it will have to examine a large fraction of the N records. Quantum mechanical systems can do several operations simultaneously due to their wave like properties. This paper gives an O (√N) step quantum mechanical algorithm for identifying that record. It is within a constant factor of the fastest possible quantum mechanical algorithm.},
   author = {Lov K. Grover},
   doi = {10.1145/237814.237866/ASSET/0A4D7788-347B-41F8-9E19-26B6DE2ACF0A/ASSETS/237814.237866.FP.PNG},
   isbn = {0897917855},
   issn = {07378017},
   journal = {Proceedings of the Annual ACM Symposium on Theory of Computing},
   month = {7},
   pages = {212-219},
   publisher = {Association for Computing Machinery},
   title = {A fast quantum mechanical algorithm for database search},
   volume = {Part F129452},
   url = {https://dl.acm.org/doi/10.1145/237814.237866},
   year = {1996}
}
@article{Schuld2015,
   abstract = {1 Machine learning refers to an area of computer science in which patterns are derived (‘learned’) from data with the goal to make sense of previously unknown inputs. As part of both artificial int...},
   author = {Maria Schuld and Ilya Sinayskiy and Francesco Petruccione},
   doi = {10.1080/00107514.2014.964942},
   issn = {13665812},
   issue = {2},
   journal = {Contemporary Physics},
   keywords = {artificial intelligence,machine learning,quantum computing,quantum machine learning},
   month = {4},
   pages = {172-185},
   publisher = {Taylor & Francis},
   title = {An introduction to quantum machine learning},
   volume = {56},
   url = {https://www.tandfonline.com/doi/abs/10.1080/00107514.2014.964942},
   year = {2015}
}
@article{Cerezo2023,
   abstract = {At the intersection of machine learning and quantum computing, Quantum Machine Learning (QML) has the potential of accelerating data analysis, especially for quantum data, with applications for quantum materials, biochemistry, and high-energy physics. Nevertheless, challenges remain regarding the trainability of QML models. Here we review current methods and applications for QML. We highlight differences between quantum and classical machine learning, with a focus on quantum neural networks and quantum deep learning. Finally, we discuss opportunities for quantum advantage with QML.},
   author = {M. Cerezo and Guillaume Verdon and Hsin-Yuan Huang and Lukasz Cincio and Patrick J. Coles},
   doi = {10.1038/s43588-022-00311-3},
   issue = {9},
   journal = {Nature Computational Science},
   month = {3},
   pages = {567-576},
   publisher = {Springer Nature},
   title = {Challenges and Opportunities in Quantum Machine Learning},
   volume = {2},
   url = {http://arxiv.org/abs/2303.09491 http://dx.doi.org/10.1038/s43588-022-00311-3},
   year = {2023}
}
@article{Su2023,
   abstract = {Quantum computing has been proven to excel in factorization issues and unordered search problems due to its capability of quantum parallelism. This unique feature allows exponential speed-up in solving certain problems. However, this advantage does not apply universally, and challenges arise when combining classical and quantum computing to achieve acceleration in computation speed. This paper aims to address these challenges by exploring the current state of quantum machine learning and benchmarking the performance of quantum and classical algorithms in terms of accuracy. Specifically, we conducted experiments with three datasets for binary classification, implementing Support Vector Machine (SVM) and Quantum SVM (QSVM) algorithms. Our findings suggest that the QSVM algorithm outperforms classical SVM on complex datasets, and the performance gap between quantum and classical models increases with dataset complexity, as simple models tend to overfit with complex datasets. While there is still a long way to go in terms of developing quantum hardware with sufficient resources, quantum machine learning holds great potential in areas such as unsupervised learning and generative models. Moving forward, more efforts are needed to explore new quantum learning models that can leverage the power of quantum mechanics to overcome the limitations of classical machine learning.},
   author = {Shi-Lei Su and He-Liang Huang and Chu Guo and Zu-En Su and Kyriaki A Tychola and Theofanis Kalampokas and George A Papakostas},
   doi = {10.3390/ELECTRONICS12112379},
   issn = {2079-9292},
   issue = {11},
   journal = {Electronics 2023, Vol. 12, Page 2379},
   keywords = {quantum classifier,quantum computer,quantum machine learning,quantum support vector machine},
   month = {5},
   pages = {2379},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Quantum Machine Learning—An Overview},
   volume = {12},
   url = {https://www.mdpi.com/2079-9292/12/11/2379/htm https://www.mdpi.com/2079-9292/12/11/2379},
   year = {2023}
}
@article{Biamonte2017,
   abstract = {Fuelled by increasing computer power and algorithmic advances, machine learning techniques have become powerful tools for finding patterns in data. Quantum systems produce atypical patterns that classical systems are thought not to produce efficiently, so it is reasonable to postulate that quantum computers may outperform classical computers on machine learning tasks. The field of quantum machine learning explores how to devise and implement quantum software that could enable machine learning that is faster than that of classical computers. Recent work has produced quantum algorithms that could act as the building blocks of machine learning programs, but the hardware and software challenges are still considerable. Quantum machine learning software could enable quantum computers to learn complex patterns in data more efficiently than classical computers are able to.},
   author = {Jacob Biamonte and Peter Wittek and Nicola Pancotti and Patrick Rebentrost and Nathan Wiebe and Seth Lloyd},
   doi = {10.1038/nature23474},
   issn = {1476-4687},
   issue = {7671},
   journal = {Nature 2017 549:7671},
   keywords = {Computer science,Quantum information,Quantum simulation},
   month = {9},
   pages = {195-202},
   pmid = {28905917},
   publisher = {Nature Publishing Group},
   title = {Quantum machine learning},
   volume = {549},
   url = {https://www.nature.com/articles/nature23474},
   year = {2017}
}
